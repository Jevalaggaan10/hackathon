{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import re\n",
    "\n",
    "def extract_tables_with_keyword(pdf_path: str, keyword: str, pages: List[int] = None) -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Extract tables from a PDF that contain a specific keyword.\n",
    "    \n",
    "    Parameters:\n",
    "    pdf_path (str): Path to the PDF file\n",
    "    keyword (str): Keyword to search for in tables\n",
    "    pages (List[int], optional): List of specific pages to search. If None, searches all pages.\n",
    "    \n",
    "    Returns:\n",
    "    List[pd.DataFrame]: List of pandas DataFrames containing the matching tables\n",
    "    \"\"\"\n",
    "    # Open the PDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    matching_tables = []\n",
    "    \n",
    "    # Determine pages to process\n",
    "    if pages is None:\n",
    "        pages = range(len(doc))\n",
    "    \n",
    "    for page_num in pages:\n",
    "        page = doc[page_num]\n",
    "        \n",
    "        # Extract tables from the page\n",
    "        tables = page.find_tables()\n",
    "        \n",
    "        if tables.tables:\n",
    "            for table in tables:\n",
    "                # Convert table to pandas DataFrame\n",
    "                df = pd.DataFrame(table.extract())\n",
    "                \n",
    "                # Check if keyword exists in any cell of the table\n",
    "                table_text = df.astype(str).values.tolist()\n",
    "                found_keyword = any(\n",
    "                    keyword.lower() in str(cell).lower()\n",
    "                    for row in table_text\n",
    "                    for cell in row\n",
    "                )\n",
    "                \n",
    "                if found_keyword:\n",
    "                    # Add page number information to help identify the table's source\n",
    "                    df.insert(0, 'Page_Number', page_num + 1)\n",
    "                    matching_tables.append(df)\n",
    "    \n",
    "    doc.close()\n",
    "    return matching_tables\n",
    "\n",
    "def process_extracted_tables(tables: List[pd.DataFrame], output_format: str = 'csv') -> Dict:\n",
    "    \"\"\"\n",
    "    Process the extracted tables and save them in the specified format.\n",
    "    \n",
    "    Parameters:\n",
    "    tables (List[pd.DataFrame]): List of tables extracted from the PDF\n",
    "    output_format (str): Format to save tables in ('csv' or 'excel')\n",
    "    \n",
    "    Returns:\n",
    "    Dict: Dictionary containing processing results and statistics\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'total_tables_found': len(tables),\n",
    "        'tables_info': []\n",
    "    }\n",
    "    \n",
    "    for i, table in enumerate(tables, 1):\n",
    "        table_info = {\n",
    "            'table_number': i,\n",
    "            'page_number': table['Page_Number'].iloc[0],\n",
    "            'rows': len(table),\n",
    "            'columns': len(table.columns)\n",
    "        }\n",
    "        results['tables_info'].append(table_info)\n",
    "        \n",
    "        # Save individual tables\n",
    "        if output_format == 'csv':\n",
    "            table.to_csv(f'extracted_table_{i}.csv', index=False)\n",
    "        elif output_format == 'excel':\n",
    "            table.to_excel(f'extracted_table_{i}.xlsx', index=False)\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 tables containing the keyword.\n",
      "Table 1 found on page 1\n",
      "Dimensions: 4 rows × 4 columns\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "pdf_path = r\"klebl_pdf_digitizer\\data\\02_Binder\\FT_XX_02-001_c_F.pdf\"\n",
    "keyword = \"Planschlüssel\"\n",
    "\n",
    "# Extract tables containing the keyword\n",
    "matching_tables = extract_tables_with_keyword(pdf_path, keyword)\n",
    "\n",
    "# Process and save the extracted tables\n",
    "results = process_extracted_tables(matching_tables, output_format='csv')\n",
    "\n",
    "# Print results\n",
    "print(f\"Found {results['total_tables_found']} tables containing the keyword.\")\n",
    "for table_info in results['tables_info']:\n",
    "    print(f\"Table {table_info['table_number']} found on page {table_info['page_number']}\")\n",
    "    print(f\"Dimensions: {table_info['rows']} rows × {table_info['columns']} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "import re\n",
    "\n",
    "def extract_tables_with_keyword(pdf_path: str, keyword: str, pages: List[int] = None) -> List[Tuple[pd.DataFrame, Dict]]:\n",
    "    \"\"\"\n",
    "    Extract tables from a PDF that contain a specific keyword, along with their location information.\n",
    "    \n",
    "    Parameters:\n",
    "    pdf_path (str): Path to the PDF file\n",
    "    keyword (str): Keyword to search for in tables\n",
    "    pages (List[int], optional): List of specific pages to search. If None, searches all pages.\n",
    "    \n",
    "    Returns:\n",
    "    List[Tuple[pd.DataFrame, Dict]]: List of tuples containing:\n",
    "        - pandas DataFrame of the table\n",
    "        - Dictionary with location information\n",
    "    \"\"\"\n",
    "    # Open the PDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    matching_tables = []\n",
    "    \n",
    "    # Determine pages to process\n",
    "    if pages is None:\n",
    "        pages = range(len(doc))\n",
    "    \n",
    "    for page_num in pages:\n",
    "        page = doc[page_num]\n",
    "        \n",
    "        # Extract tables from the page\n",
    "        tables = page.find_tables()\n",
    "        \n",
    "        if tables.tables:\n",
    "            for table_idx, table in enumerate(tables):\n",
    "                # Convert table to pandas DataFrame\n",
    "                df = pd.DataFrame(table.extract())\n",
    "                \n",
    "                # Check if keyword exists in any cell of the table\n",
    "                table_text = df.astype(str).values.tolist()\n",
    "                found_keyword = False\n",
    "                keyword_locations = []\n",
    "                \n",
    "                # Search for keyword and record its location\n",
    "                for row_idx, row in enumerate(table_text):\n",
    "                    for col_idx, cell in enumerate(row):\n",
    "                        if keyword.lower() in str(cell).lower():\n",
    "                            found_keyword = True\n",
    "                            keyword_locations.append({\n",
    "                                'row': row_idx,\n",
    "                                'column': col_idx,\n",
    "                                'cell_content': cell\n",
    "                            })\n",
    "                \n",
    "                if found_keyword:\n",
    "                    # Get table boundaries on the page\n",
    "                    table_rect = table.bbox  # Gets coordinates (x0, y0, x1, y1)\n",
    "                    \n",
    "                    # Location information\n",
    "                    location_info = {\n",
    "                        'page_number': page_num + 1,\n",
    "                        'table_number': table_idx + 1,\n",
    "                        'keyword_locations': keyword_locations,\n",
    "                        'table_coordinates': {\n",
    "                            'top_left': (table_rect.x0, table_rect.y0),\n",
    "                            'bottom_right': (table_rect.x1, table_rect.y1)\n",
    "                        },\n",
    "                        'table_dimensions': {\n",
    "                            'rows': len(df),\n",
    "                            'columns': len(df.columns)\n",
    "                        },\n",
    "                        'surrounding_text': get_surrounding_text(page, table_rect)\n",
    "                    }\n",
    "                    \n",
    "                    matching_tables.append((df, location_info))\n",
    "    \n",
    "    doc.close()\n",
    "    return matching_tables\n",
    "\n",
    "def get_surrounding_text(page, table_rect, margin=50):\n",
    "    \"\"\"\n",
    "    Extract text surrounding the table within a specified margin.\n",
    "    \n",
    "    Parameters:\n",
    "    page: PDF page object\n",
    "    table_rect: Rectangle coordinates of the table\n",
    "    margin: Pixel margin around the table to search for text\n",
    "    \n",
    "    Returns:\n",
    "    Dict: Text before and after the table\n",
    "    \"\"\"\n",
    "    # Create rectangles for areas above and below the table\n",
    "    above_rect = fitz.Rect(\n",
    "        table_rect.x0,\n",
    "        max(0, table_rect.y0 - margin),\n",
    "        table_rect.x1,\n",
    "        table_rect.y0\n",
    "    )\n",
    "    \n",
    "    below_rect = fitz.Rect(\n",
    "        table_rect.x0,\n",
    "        table_rect.y1,\n",
    "        table_rect.x1,\n",
    "        min(page.rect.height, table_rect.y1 + margin)\n",
    "    )\n",
    "    \n",
    "    # Extract text from these areas\n",
    "    return {\n",
    "        'text_above': page.get_text(\"text\", clip=above_rect).strip(),\n",
    "        'text_below': page.get_text(\"text\", clip=below_rect).strip()\n",
    "    }\n",
    "\n",
    "def save_table_with_context(table_data: Tuple[pd.DataFrame, Dict], output_prefix: str, format: str = 'csv'):\n",
    "    \"\"\"\n",
    "    Save a table and its context information.\n",
    "    \n",
    "    Parameters:\n",
    "    table_data: Tuple containing DataFrame and location information\n",
    "    output_prefix: Prefix for output files\n",
    "    format: Output format ('csv' or 'excel')\n",
    "    \"\"\"\n",
    "    df, info = table_data\n",
    "    \n",
    "    # Save table data\n",
    "    if format == 'csv':\n",
    "        df.to_csv(f\"{output_prefix}_table.csv\", index=False)\n",
    "    elif format == 'excel':\n",
    "        df.to_excel(f\"{output_prefix}_table.xlsx\", index=False)\n",
    "    \n",
    "    # Save context information\n",
    "    context_df = pd.DataFrame([{\n",
    "        'Page Number': info['page_number'],\n",
    "        'Table Number': info['table_number'],\n",
    "        'Rows': info['table_dimensions']['rows'],\n",
    "        'Columns': info['table_dimensions']['columns'],\n",
    "        'Text Above': info['surrounding_text']['text_above'],\n",
    "        'Text Below': info['surrounding_text']['text_below'],\n",
    "        'Keyword Locations': str(info['keyword_locations'])\n",
    "    }])\n",
    "    \n",
    "    if format == 'csv':\n",
    "        context_df.to_csv(f\"{output_prefix}_context.csv\", index=False)\n",
    "    elif format == 'excel':\n",
    "        context_df.to_excel(f\"{output_prefix}_context.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'x0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m keyword \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlanschlüssel\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Extract tables containing the keyword with their location information\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m matching_tables \u001b[38;5;241m=\u001b[39m \u001b[43mextract_tables_with_keyword\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeyword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Process each table and its context\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (table, info) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(matching_tables, \u001b[38;5;241m1\u001b[39m):\n",
      "Cell \u001b[1;32mIn[3], line 65\u001b[0m, in \u001b[0;36mextract_tables_with_keyword\u001b[1;34m(pdf_path, keyword, pages)\u001b[0m\n\u001b[0;32m     57\u001b[0m                 table_rect \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mbbox  \u001b[38;5;66;03m# Gets coordinates (x0, y0, x1, y1)\u001b[39;00m\n\u001b[0;32m     59\u001b[0m                 \u001b[38;5;66;03m# Location information\u001b[39;00m\n\u001b[0;32m     60\u001b[0m                 location_info \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     61\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_number\u001b[39m\u001b[38;5;124m'\u001b[39m: page_num \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     62\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable_number\u001b[39m\u001b[38;5;124m'\u001b[39m: table_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     63\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeyword_locations\u001b[39m\u001b[38;5;124m'\u001b[39m: keyword_locations,\n\u001b[0;32m     64\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable_coordinates\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m---> 65\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_left\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[43mtable_rect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx0\u001b[49m, table_rect\u001b[38;5;241m.\u001b[39my0),\n\u001b[0;32m     66\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottom_right\u001b[39m\u001b[38;5;124m'\u001b[39m: (table_rect\u001b[38;5;241m.\u001b[39mx1, table_rect\u001b[38;5;241m.\u001b[39my1)\n\u001b[0;32m     67\u001b[0m                     },\n\u001b[0;32m     68\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable_dimensions\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[0;32m     69\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrows\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(df),\n\u001b[0;32m     70\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m     71\u001b[0m                     },\n\u001b[0;32m     72\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrounding_text\u001b[39m\u001b[38;5;124m'\u001b[39m: get_surrounding_text(page, table_rect)\n\u001b[0;32m     73\u001b[0m                 }\n\u001b[0;32m     75\u001b[0m                 matching_tables\u001b[38;5;241m.\u001b[39mappend((df, location_info))\n\u001b[0;32m     77\u001b[0m doc\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'x0'"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "pdf_path = r\"klebl_pdf_digitizer\\data\\02_Binder\\FT_XX_02-001_c_F.pdf\"\n",
    "keyword = \"Planschlüssel\"\n",
    "\n",
    "# Extract tables containing the keyword with their location information\n",
    "matching_tables = extract_tables_with_keyword(pdf_path, keyword)\n",
    "\n",
    "# Process each table and its context\n",
    "for i, (table, info) in enumerate(matching_tables, 1):\n",
    "    print(f\"\\nTable {i} found on page {info['page_number']}:\")\n",
    "    print(f\"Dimensions: {info['table_dimensions']['rows']} rows × {info['table_dimensions']['columns']} columns\")\n",
    "    print(\"\\nKeyword found in cells:\")\n",
    "    for loc in info['keyword_locations']:\n",
    "        print(f\"Row {loc['row']}, Column {loc['column']}: {loc['cell_content']}\")\n",
    "    print(\"\\nSurrounding text:\")\n",
    "    print(\"Above:\", info['surrounding_text']['text_above'])\n",
    "    print(\"Below:\", info['surrounding_text']['text_below'])\n",
    "    \n",
    "    # Save table and context information\n",
    "    save_table_with_context((table, info), f\"table_{i}\", format='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "import re\n",
    "\n",
    "def extract_tables_with_keyword(pdf_path: str, keyword: str, pages: List[int] = None) -> List[Tuple[pd.DataFrame, Dict]]:\n",
    "    \"\"\"\n",
    "    Extract tables from a PDF that contain a specific keyword, along with their location information.\n",
    "    \n",
    "    Parameters:\n",
    "    pdf_path (str): Path to the PDF file\n",
    "    keyword (str): Keyword to search for in tables\n",
    "    pages (List[int], optional): List of specific pages to search. If None, searches all pages.\n",
    "    \n",
    "    Returns:\n",
    "    List[Tuple[pd.DataFrame, Dict]]: List of tuples containing:\n",
    "        - pandas DataFrame of the table\n",
    "        - Dictionary with location information\n",
    "    \"\"\"\n",
    "    # Open the PDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    matching_tables = []\n",
    "    \n",
    "    # Determine pages to process\n",
    "    if pages is None:\n",
    "        pages = range(len(doc))\n",
    "    \n",
    "    for page_num in pages:\n",
    "        page = doc[page_num]\n",
    "        \n",
    "        # Extract tables from the page\n",
    "        tables = page.find_tables()\n",
    "        \n",
    "        if tables.tables:\n",
    "            for table_idx, table in enumerate(tables):\n",
    "                # Convert table to pandas DataFrame\n",
    "                df = pd.DataFrame(table.extract())\n",
    "                \n",
    "                # Check if keyword exists in any cell of the table\n",
    "                table_text = df.astype(str).values.tolist()\n",
    "                found_keyword = False\n",
    "                keyword_locations = []\n",
    "                \n",
    "                # Search for keyword and record its location\n",
    "                for row_idx, row in enumerate(table_text):\n",
    "                    for col_idx, cell in enumerate(row):\n",
    "                        if keyword.lower() in str(cell).lower():\n",
    "                            found_keyword = True\n",
    "                            keyword_locations.append({\n",
    "                                'row': row_idx,\n",
    "                                'column': col_idx,\n",
    "                                'cell_content': cell\n",
    "                            })\n",
    "                \n",
    "                if found_keyword:\n",
    "                    # Get table boundaries on the page - bbox returns (x0, y0, x1, y1)\n",
    "                    x0, y0, x1, y1 = table.bbox\n",
    "                    \n",
    "                    # Location information\n",
    "                    location_info = {\n",
    "                        'page_number': page_num + 1,\n",
    "                        'table_number': table_idx + 1,\n",
    "                        'keyword_locations': keyword_locations,\n",
    "                        'table_coordinates': {\n",
    "                            'top_left': (x0, y0),\n",
    "                            'bottom_right': (x1, y1)\n",
    "                        },\n",
    "                        'table_dimensions': {\n",
    "                            'rows': len(df),\n",
    "                            'columns': len(df.columns)\n",
    "                        },\n",
    "                        'surrounding_text': get_surrounding_text(page, (x0, y0, x1, y1))\n",
    "                    }\n",
    "                    \n",
    "                    matching_tables.append((df, location_info))\n",
    "    \n",
    "    doc.close()\n",
    "    return matching_tables\n",
    "\n",
    "def get_surrounding_text(page, table_coords: Tuple[float, float, float, float], margin=50):\n",
    "    \"\"\"\n",
    "    Extract text surrounding the table within a specified margin.\n",
    "    \n",
    "    Parameters:\n",
    "    page: PDF page object\n",
    "    table_coords: Tuple of (x0, y0, x1, y1) coordinates\n",
    "    margin: Pixel margin around the table to search for text\n",
    "    \n",
    "    Returns:\n",
    "    Dict: Text before and after the table\n",
    "    \"\"\"\n",
    "    x0, y0, x1, y1 = table_coords\n",
    "    \n",
    "    # Create rectangles for areas above and below the table\n",
    "    above_rect = fitz.Rect(\n",
    "        x0,\n",
    "        max(0, y0 - margin),\n",
    "        x1,\n",
    "        y0\n",
    "    )\n",
    "    \n",
    "    below_rect = fitz.Rect(\n",
    "        x0,\n",
    "        y1,\n",
    "        x1,\n",
    "        min(page.rect.height, y1 + margin)\n",
    "    )\n",
    "    \n",
    "    # Extract text from these areas\n",
    "    return {\n",
    "        'text_above': page.get_text(\"text\", clip=above_rect).strip(),\n",
    "        'text_below': page.get_text(\"text\", clip=below_rect).strip()\n",
    "    }\n",
    "\n",
    "def save_table_with_context(table_data: Tuple[pd.DataFrame, Dict], output_prefix: str, format: str = 'csv'):\n",
    "    \"\"\"\n",
    "    Save a table and its context information.\n",
    "    \n",
    "    Parameters:\n",
    "    table_data: Tuple containing DataFrame and location information\n",
    "    output_prefix: Prefix for output files\n",
    "    format: Output format ('csv' or 'excel')\n",
    "    \"\"\"\n",
    "    df, info = table_data\n",
    "    \n",
    "    # Save table data\n",
    "    if format == 'csv':\n",
    "        df.to_csv(f\"{output_prefix}_table.csv\", index=False)\n",
    "    elif format == 'excel':\n",
    "        df.to_excel(f\"{output_prefix}_table.xlsx\", index=False)\n",
    "    \n",
    "    # Save context information\n",
    "    context_df = pd.DataFrame([{\n",
    "        'Page Number': info['page_number'],\n",
    "        'Table Number': info['table_number'],\n",
    "        'Rows': info['table_dimensions']['rows'],\n",
    "        'Columns': info['table_dimensions']['columns'],\n",
    "        'Text Above': info['surrounding_text']['text_above'],\n",
    "        'Text Below': info['surrounding_text']['text_below'],\n",
    "        'Keyword Locations': str(info['keyword_locations'])\n",
    "    }])\n",
    "    \n",
    "    if format == 'csv':\n",
    "        context_df.to_csv(f\"{output_prefix}_context.csv\", index=False)\n",
    "    elif format == 'excel':\n",
    "        context_df.to_excel(f\"{output_prefix}_context.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table 1 found on page 1:\n",
      "Dimensions: 4 rows × 3 columns\n",
      "\n",
      "Keyword found in cells:\n",
      "Row 3, Column 0: Planschlüssel\n"
     ]
    }
   ],
   "source": [
    "pdf_path = r\"klebl_pdf_digitizer\\data\\02_Binder\\FT_XX_02-001_c_F.pdf\"\n",
    "keyword = \"Planschlüssel\"\n",
    "\n",
    "# Extract tables containing the keyword with their location information\n",
    "matching_tables = extract_tables_with_keyword(pdf_path, keyword)\n",
    "\n",
    "# Process each table and its context\n",
    "for i, (table, info) in enumerate(matching_tables, 1):\n",
    "    print(f\"\\nTable {i} found on page {info['page_number']}:\")\n",
    "    print(f\"Dimensions: {info['table_dimensions']['rows']} rows × {info['table_dimensions']['columns']} columns\")\n",
    "    print(\"\\nKeyword found in cells:\")\n",
    "    for loc in info['keyword_locations']:\n",
    "        print(f\"Row {loc['row']}, Column {loc['column']}: {loc['cell_content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "import re\n",
    "\n",
    "def extract_tables_with_keyword(pdf_path: str, keyword: str, pages: List[int] = None) -> List[Tuple[pd.DataFrame, Dict]]:\n",
    "    \"\"\"\n",
    "    Extract tables from a PDF that contain a specific keyword, along with their location information.\n",
    "    \n",
    "    Parameters:\n",
    "    pdf_path (str): Path to the PDF file\n",
    "    keyword (str): Keyword to search for in tables\n",
    "    pages (List[int], optional): List of specific pages to search. If None, searches all pages.\n",
    "    \n",
    "    Returns:\n",
    "    List[Tuple[pd.DataFrame, Dict]]: List of tuples containing:\n",
    "        - pandas DataFrame of the table\n",
    "        - Dictionary with location information\n",
    "    \"\"\"\n",
    "    # Open the PDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    matching_tables = []\n",
    "    \n",
    "    # Determine pages to process\n",
    "    if pages is None:\n",
    "        pages = range(len(doc))\n",
    "    \n",
    "    for page_num in pages:\n",
    "        page = doc[page_num]\n",
    "        \n",
    "        # Extract tables from the page\n",
    "        tables = page.find_tables()\n",
    "        \n",
    "        if tables.tables:\n",
    "            for table_idx, table in enumerate(tables):\n",
    "                # Convert table to pandas DataFrame\n",
    "                df = pd.DataFrame(table.extract())\n",
    "                \n",
    "                # Check if keyword exists in any cell of the table\n",
    "                table_text = df.astype(str).values.tolist()\n",
    "                found_keyword = False\n",
    "                keyword_locations = []\n",
    "                \n",
    "                # Search for keyword and record its location\n",
    "                for row_idx, row in enumerate(table_text):\n",
    "                    for col_idx, cell in enumerate(row):\n",
    "                        if keyword.lower() in str(cell).lower():\n",
    "                            found_keyword = True\n",
    "                            keyword_locations.append({\n",
    "                                'row': row_idx,\n",
    "                                'column': col_idx,\n",
    "                                'cell_content': cell\n",
    "                            })\n",
    "                \n",
    "                if found_keyword:\n",
    "                    # Get table boundaries\n",
    "                    x0, y0, x1, y1 = table.bbox\n",
    "                    \n",
    "                    # Location information\n",
    "                    location_info = {\n",
    "                        'page_number': page_num + 1,\n",
    "                        'table_number': table_idx + 1,\n",
    "                        'keyword_locations': keyword_locations,\n",
    "                        'table_coordinates': {\n",
    "                            'top_left': (x0, y0),\n",
    "                            'bottom_right': (x1, y1)\n",
    "                        },\n",
    "                        'table_dimensions': {\n",
    "                            'rows': len(df),\n",
    "                            'columns': len(df.columns)\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    matching_tables.append((df, location_info))\n",
    "    \n",
    "    doc.close()\n",
    "    return matching_tables\n",
    "\n",
    "def display_full_table(table_data: Tuple[pd.DataFrame, Dict]):\n",
    "    \"\"\"\n",
    "    Display the full table content along with its location information.\n",
    "    \n",
    "    Parameters:\n",
    "    table_data: Tuple containing DataFrame and location information\n",
    "    \"\"\"\n",
    "    df, info = table_data\n",
    "    \n",
    "    print(f\"\\nTable found on page {info['page_number']} (Table #{info['table_number']}):\")\n",
    "    print(f\"Dimensions: {info['table_dimensions']['rows']} rows × {info['table_dimensions']['columns']} columns\")\n",
    "    print(\"\\nKeyword found in positions:\")\n",
    "    for loc in info['keyword_locations']:\n",
    "        print(f\"Row {loc['row'] + 1}, Column {loc['column'] + 1}\")\n",
    "    \n",
    "    print(\"\\nFull Table Content:\")\n",
    "    # Set display options to show all rows and columns\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    print(df)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separator between tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table found on page 1 (Table #9):\n",
      "Dimensions: 4 rows × 3 columns\n",
      "\n",
      "Keyword found in positions:\n",
      "Row 4, Column 1\n",
      "\n",
      "Full Table Content:\n",
      "                                                   0  \\\n",
      "0  Datum 16.12.2019 B a u v o r h a b e n / B a u...   \n",
      "1      Gez. Jan. S\\nNeub\\nstat.Pos B01\\nMaßstab 1:25   \n",
      "2                                               None   \n",
      "3                                      Planschlüssel   \n",
      "\n",
      "                                                   1  \\\n",
      "0                                               None   \n",
      "1  and- und Baustoffwerke Neumarkt GmbH & Co.KG\\n...   \n",
      "2                                               None   \n",
      "3                                   FT_XX_02-001_c_F   \n",
      "\n",
      "                           2  \n",
      "0                       None  \n",
      "1                     819-19  \n",
      "2  Plan. Nr / Index / Status  \n",
      "3                       None  \n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_path = r\"klebl_pdf_digitizer\\data\\02_Binder\\FT_XX_02-001_c_F.pdf\"\n",
    "keyword = \"Planschlüssel\"\n",
    "\n",
    "# Extract tables containing the keyword\n",
    "matching_tables = extract_tables_with_keyword(pdf_path, keyword)\n",
    "\n",
    "# Display full content of each matching table\n",
    "for table_data in matching_tables:\n",
    "    display_full_table(table_data)\n",
    "    \n",
    "# Optionally, save specific tables to CSV or Excel\n",
    "for i, (df, info) in enumerate(matching_tables, 1):\n",
    "    df.to_csv(f\"table_{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "import re\n",
    "\n",
    "def clean_table_data(df):\n",
    "    \"\"\"\n",
    "    Clean and format table data for better readability.\n",
    "    \"\"\"\n",
    "    # Replace NaN with empty string\n",
    "    df = df.fillna('')\n",
    "    \n",
    "    # Clean whitespace and normalize spaces\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].astype(str).apply(lambda x: ' '.join(x.split()))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_tables_with_keyword(pdf_path: str, keyword: str, pages: List[int] = None) -> List[Tuple[pd.DataFrame, Dict]]:\n",
    "    \"\"\"\n",
    "    Extract tables from a PDF that contain a specific keyword.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    matching_tables = []\n",
    "    \n",
    "    # Determine pages to process\n",
    "    if pages is None:\n",
    "        pages = range(len(doc))\n",
    "    \n",
    "    for page_num in pages:\n",
    "        page = doc[page_num]\n",
    "        tables = page.find_tables()\n",
    "        \n",
    "        if tables.tables:\n",
    "            for table_idx, table in enumerate(tables):\n",
    "                # Convert table to pandas DataFrame and clean it\n",
    "                df = clean_table_data(pd.DataFrame(table.extract()))\n",
    "                \n",
    "                # Check if keyword exists in any cell\n",
    "                table_text = df.astype(str).values.tolist()\n",
    "                found_keyword = False\n",
    "                keyword_locations = []\n",
    "                \n",
    "                for row_idx, row in enumerate(table_text):\n",
    "                    for col_idx, cell in enumerate(row):\n",
    "                        if keyword.lower() in str(cell).lower():\n",
    "                            found_keyword = True\n",
    "                            keyword_locations.append({\n",
    "                                'row': row_idx,\n",
    "                                'column': col_idx,\n",
    "                                'cell_content': cell\n",
    "                            })\n",
    "                \n",
    "                if found_keyword:\n",
    "                    matching_tables.append((df, {\n",
    "                        'page_number': page_num + 1,\n",
    "                        'table_number': table_idx + 1,\n",
    "                        'keyword_locations': keyword_locations\n",
    "                    }))\n",
    "    \n",
    "    doc.close()\n",
    "    return matching_tables\n",
    "\n",
    "def format_table_as_text(df: pd.DataFrame, info: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Format table data as readable text.\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    \n",
    "    # Header\n",
    "    output.append(f\"=== Table found on Page {info['page_number']} ===\\n\")\n",
    "    \n",
    "    # Format each row of the table\n",
    "    for row_idx, row in df.iterrows():\n",
    "        row_content = []\n",
    "        for col_idx, value in enumerate(row):\n",
    "            # Check if this cell contains the keyword\n",
    "            is_keyword_cell = any(\n",
    "                loc['row'] == row_idx and loc['column'] == col_idx \n",
    "                for loc in info['keyword_locations']\n",
    "            )\n",
    "            \n",
    "            # Format the cell value\n",
    "            cell_text = str(value).strip()\n",
    "            if is_keyword_cell:\n",
    "                cell_text = f\"*{cell_text}*\"  # Mark keyword cells with asterisks\n",
    "            \n",
    "            if cell_text:  # Only add non-empty cells\n",
    "                row_content.append(cell_text)\n",
    "        \n",
    "        if row_content:  # Only add non-empty rows\n",
    "            output.append(\" | \".join(row_content))\n",
    "    \n",
    "    output.append(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    return \"\\n\".join(output)\n",
    "\n",
    "def display_tables(matching_tables: List[Tuple[pd.DataFrame, Dict]]):\n",
    "    \"\"\"\n",
    "    Display all matching tables in a clean, readable format.\n",
    "    \"\"\"\n",
    "    for df, info in matching_tables:\n",
    "        formatted_text = format_table_as_text(df, info)\n",
    "        print(formatted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Table found on Page 1 ===\n",
      "\n",
      "Datum 16.12.2019 B a u v o r h a b e n / B a u t e i l Auftr. Nr\n",
      "Gez. Jan. S Neub stat.Pos B01 Maßstab 1:25 | and- und Baustoffwerke Neumarkt GmbH & Co.KG au einer Ausstellungshalle, und Containerhalle mit Büro Dachbinder Pos. 02-001 | 819-19\n",
      "Plan. Nr / Index / Status\n",
      "*Planschlüssel* | FT_XX_02-001_c_F\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pdf_path = r\"klebl_pdf_digitizer\\data\\02_Binder\\FT_XX_02-001_c_F.pdf\"\n",
    "keyword = \"Planschlüssel\"\n",
    "\n",
    "# Extract and display tables\n",
    "matching_tables = extract_tables_with_keyword(pdf_path, keyword)\n",
    "display_tables(matching_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "import os\n",
    "\n",
    "def extract_table_with_image(pdf_path: str, keyword: str, output_dir: str = \"table_images\", pages: List[int] = None):\n",
    "    \"\"\"\n",
    "    Extract tables containing keyword and save their images using coordinates.\n",
    "    \n",
    "    Parameters:\n",
    "    pdf_path (str): Path to the PDF file\n",
    "    keyword (str): Keyword to search for in tables\n",
    "    output_dir (str): Directory to save the cropped table images\n",
    "    pages (List[int], optional): List of specific pages to search. If None, searches all pages.\n",
    "    \n",
    "    Returns:\n",
    "    List[Dict]: List of dictionaries containing table information and image paths\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Open the PDF\n",
    "    doc = fitz.open(pdf_path)\n",
    "    tables_info = []\n",
    "    \n",
    "    # Determine pages to process\n",
    "    if pages is None:\n",
    "        pages = range(len(doc))\n",
    "    \n",
    "    for page_num in pages:\n",
    "        page = doc[page_num]\n",
    "        \n",
    "        # Get page dimensions\n",
    "        page_width = page.rect.width\n",
    "        page_height = page.rect.height\n",
    "        \n",
    "        # Convert PDF page to image\n",
    "        pix = page.get_pixmap(matrix=fitz.Matrix(300/72, 300/72))  # 300 DPI\n",
    "        img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, 3)\n",
    "        \n",
    "        # Extract tables from the page\n",
    "        tables = page.find_tables()\n",
    "        \n",
    "        if tables.tables:\n",
    "            for table_idx, table in enumerate(tables):\n",
    "                # Convert table to DataFrame\n",
    "                df = pd.DataFrame(table.extract())\n",
    "                \n",
    "                # Check if keyword exists in any cell\n",
    "                table_text = df.astype(str).values.tolist()\n",
    "                found_keyword = False\n",
    "                keyword_locations = []\n",
    "                \n",
    "                for row_idx, row in enumerate(table_text):\n",
    "                    for col_idx, cell in enumerate(row):\n",
    "                        if keyword.lower() in str(cell).lower():\n",
    "                            found_keyword = True\n",
    "                            keyword_locations.append({\n",
    "                                'row': row_idx,\n",
    "                                'column': col_idx,\n",
    "                                'cell_content': cell\n",
    "                            })\n",
    "                \n",
    "                if found_keyword:\n",
    "                    # Get table coordinates\n",
    "                    x0, y0, x1, y1 = table.bbox\n",
    "                    \n",
    "                    # Scale coordinates to match image resolution\n",
    "                    scale = 300/72  # Scale factor for 300 DPI\n",
    "                    x0, y0, x1, y1 = [int(coord * scale) for coord in [x0, y0, x1, y1]]\n",
    "                    \n",
    "                    # Crop the image\n",
    "                    table_image = img[y0:y1, x0:x1]\n",
    "                    \n",
    "                    # Save the cropped image\n",
    "                    image_path = os.path.join(output_dir, f\"table_page{page_num+1}_idx{table_idx}.png\")\n",
    "                    cv2.imwrite(image_path, cv2.cvtColor(table_image, cv2.COLOR_RGB2BGR))\n",
    "                    \n",
    "                    # Store table information\n",
    "                    table_info = {\n",
    "                        'page_number': page_num + 1,\n",
    "                        'table_number': table_idx + 1,\n",
    "                        'keyword_locations': keyword_locations,\n",
    "                        'coordinates': {\n",
    "                            'x0': x0,\n",
    "                            'y0': y0,\n",
    "                            'x1': x1,\n",
    "                            'y1': y1,\n",
    "                            'width': x1 - x0,\n",
    "                            'height': y1 - y0\n",
    "                        },\n",
    "                        'original_pdf_size': {\n",
    "                            'width': page_width,\n",
    "                            'height': page_height\n",
    "                        },\n",
    "                        'image_path': image_path,\n",
    "                        'dataframe': df\n",
    "                    }\n",
    "                    tables_info.append(table_info)\n",
    "    \n",
    "    doc.close()\n",
    "    return tables_info\n",
    "\n",
    "def display_table_info(table_info: Dict):\n",
    "    \"\"\"\n",
    "    Display information about the extracted table.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Table found on Page {table_info['page_number']} ===\")\n",
    "    print(\"\\nCoordinates (in pixels at 300 DPI):\")\n",
    "    print(f\"Top-left: ({table_info['coordinates']['x0']}, {table_info['coordinates']['y0']})\")\n",
    "    print(f\"Bottom-right: ({table_info['coordinates']['x1']}, {table_info['coordinates']['y1']})\")\n",
    "    print(f\"Width: {table_info['coordinates']['width']} pixels\")\n",
    "    print(f\"Height: {table_info['coordinates']['height']} pixels\")\n",
    "    print(f\"\\nImage saved to: {table_info['image_path']}\")\n",
    "    print(\"\\nKeyword found in:\")\n",
    "    for loc in table_info['keyword_locations']:\n",
    "        print(f\"Row {loc['row'] + 1}, Column {loc['column'] + 1}: {loc['cell_content']}\")\n",
    "    print(\"\\nTable content:\")\n",
    "    print(table_info['dataframe'])\n",
    "    print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_tables_with_keyword' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m keyword \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlanschlüssel\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Extract tables containing the keyword\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m matching_tables \u001b[38;5;241m=\u001b[39m \u001b[43mextract_tables_with_keyword\u001b[49m(pdf_path, keyword)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Display full content of each matching table\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table_data \u001b[38;5;129;01min\u001b[39;00m matching_tables:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_tables_with_keyword' is not defined"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "pdf_path = r\"klebl_pdf_digitizer\\data\\02_Binder\\FT_XX_02-001_c_F.pdf\"\n",
    "keyword = \"Planschlüssel\"\n",
    "\n",
    "# Extract tables containing the keyword\n",
    "matching_tables = extract_tables_with_keyword(pdf_path, keyword)\n",
    "\n",
    "# Display full content of each matching table\n",
    "for table_data in matching_tables:\n",
    "    display_full_table(table_data)\n",
    "    \n",
    "# Optionally, save specific tables to CSV or Excel\n",
    "for i, (df, info) in enumerate(matching_tables, 1):\n",
    "    df.to_csv(f\"table_{i}.csv\", index=False)\n",
    "\n",
    "# Extract tables and save images\n",
    "tables_info = extract_table_with_image(pdf_path, keyword)\n",
    "\n",
    "# Display information for each table\n",
    "for table_info in tables_info:\n",
    "    display_table_info(table_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "import os\n",
    "\n",
    "def get_table_images(pdf_path: str, keyword: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Extract tables containing keyword and convert them to PNG images.\n",
    "    \n",
    "    Parameters:\n",
    "    pdf_path (str): Path to the PDF file\n",
    "    keyword (str): Keyword to search for in tables\n",
    "    \n",
    "    Returns:\n",
    "    List[Dict]: List of dictionaries containing table images and their information\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    table_images = []\n",
    "    \n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        \n",
    "        # Convert PDF page to image at 300 DPI\n",
    "        zoom = 300/72  # 300 DPI resolution\n",
    "        mat = fitz.Matrix(zoom, zoom)\n",
    "        pix = page.get_pixmap(matrix=mat)\n",
    "        img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, 3)\n",
    "        \n",
    "        # Find tables in the page\n",
    "        tables = page.find_tables()\n",
    "        \n",
    "        if tables.tables:\n",
    "            for table_idx, table in enumerate(tables):\n",
    "                # Convert table to DataFrame to search for keyword\n",
    "                df = pd.DataFrame(table.extract())\n",
    "                \n",
    "                # Search for keyword\n",
    "                if df.astype(str).apply(lambda x: x.str.contains(keyword, case=False)).any().any():\n",
    "                    # Get table coordinates\n",
    "                    x0, y0, x1, y1 = table.bbox\n",
    "                    \n",
    "                    # Scale coordinates to match image resolution\n",
    "                    x0, y0, x1, y1 = [int(coord * zoom) for coord in [x0, y0, x1, y1]]\n",
    "                    \n",
    "                    # Add small padding around the table (optional)\n",
    "                    padding = 10\n",
    "                    x0 = max(0, x0 - padding)\n",
    "                    y0 = max(0, y0 - padding)\n",
    "                    x1 = min(img.shape[1], x1 + padding)\n",
    "                    y1 = min(img.shape[0], y1 + padding)\n",
    "                    \n",
    "                    # Crop the table image\n",
    "                    table_img = img[y0:y1, x0:x1]\n",
    "                    \n",
    "                    # Convert RGB to BGR for OpenCV\n",
    "                    table_img_bgr = cv2.cvtColor(table_img, cv2.COLOR_RGB2BGR)\n",
    "                    \n",
    "                    table_info = {\n",
    "                        'page_number': page_num + 1,\n",
    "                        'table_number': table_idx + 1,\n",
    "                        'coordinates': {\n",
    "                            'x0': x0, 'y0': y0,\n",
    "                            'x1': x1, 'y1': y1,\n",
    "                            'width': x1 - x0,\n",
    "                            'height': y1 - y0\n",
    "                        },\n",
    "                        'image': table_img_bgr  # The actual image data\n",
    "                    }\n",
    "                    \n",
    "                    table_images.append(table_info)\n",
    "    \n",
    "    doc.close()\n",
    "    return table_images\n",
    "\n",
    "def save_table_images(table_images: List[Dict], output_dir: str = \"table_images\"):\n",
    "    \"\"\"\n",
    "    Save the extracted table images to files.\n",
    "    \n",
    "    Parameters:\n",
    "    table_images: List of dictionaries containing table images and info\n",
    "    output_dir: Directory to save the images\n",
    "    \n",
    "    Returns:\n",
    "    List[str]: List of saved image paths\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    saved_paths = []\n",
    "    \n",
    "    for table in table_images:\n",
    "        # Generate filename\n",
    "        filename = f\"table_page{table['page_number']}_num{table['table_number']}.png\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        \n",
    "        # Save image\n",
    "        cv2.imwrite(filepath, table['image'])\n",
    "        saved_paths.append(filepath)\n",
    "        \n",
    "        print(f\"Saved table image from page {table['page_number']} to: {filepath}\")\n",
    "        print(f\"Table dimensions: {table['coordinates']['width']}x{table['coordinates']['height']} pixels\")\n",
    "    \n",
    "    return saved_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# If you want to display an image (if you're in a Jupyter notebook)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(cv2\u001b[38;5;241m.\u001b[39mcvtColor(\u001b[43mtable_images\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m], cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "pdf_path = r\"klebl_pdf_digitizer\\data\\02_Binder\\FT_XX_02-001_c_F.pdf\"\n",
    "keyword = \"Breite\"\n",
    "\n",
    "# Get table images\n",
    "table_images = get_table_images(pdf_path, keyword)\n",
    "\n",
    "# Save the images\n",
    "saved_files = save_table_images(table_images)\n",
    "\n",
    "# If you want to display an image (if you're in a Jupyter notebook)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(cv2.cvtColor(table_images[0]['image'], cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# If you want to do additional processing on a specific table image\n",
    "for table in table_images:\n",
    "    img = table['image']\n",
    "    # Example: Apply some image processing\n",
    "    # enhanced_img = cv2.enhance(img)  # placeholder for any CV operation\n",
    "    print(f\"Found table on page {table['page_number']}\")\n",
    "    print(f\"Coordinates: {table['coordinates']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\mgsuk\\miniconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\mgsuk\\miniconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mgsuk\\miniconda3\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\mgsuk\\miniconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\mgsuk\\miniconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\mgsuk\\miniconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mgsuk\\miniconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\mgsuk\\miniconda3\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\mgsuk\\miniconda3\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\mgsuk\\miniconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mgsuk\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
